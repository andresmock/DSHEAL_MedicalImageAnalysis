# **DSHEAL_project_FS25_GaMo**
Medical Image Analysis - Malaria Detection Using Blood Smear Images

## Table of Content
- [Task](#task)
- [Short Project Description (Abstract)](#short-project-description-abstract)
- [Structured Project Directory](#structured-project-directory)
- [Dataset Details (Source & Statistics)](#dataset-details-source--statistics)
- [Data Preprocessing](#data-preprocessing)
- [Installation and Usage Instructions](#installation-and-usage-instructions)
  - [Data Download](#data-download)
  - [Environment Management: Setting up the Environment](#environment-management-setting-up-the-environment)
- [Evaluation](#evaluation)
- [Model Performance Summary](#model-performance-summary)
- [Team Members and Contributions](#team-members-and-contributions)


---


## Task
take a look at: https://github.zhaw.ch/ADLS-Digital-Health/DSHEAL-FS25/blob/main/project/assignment.md


---


## Short Project Description (Abstract)

This project focuses on classifying blood smear images to detect malaria-infected cells using Convolutional Neural Networks (CNNs). The dataset used is publicly available on Kaggle and contains pre-split images labeled as either *Parasitized* or *Uninfected*.

We first implemented a simple baseline CNN, which already achieved strong performance using the default train/val/test split. To explore potential improvements, we developed a more flexible CNN architecture with support for K-Fold cross-validation and hyperparameter optimization via Optuna. However, these enhancements did not significantly improve the results, indicating that the original dataset split and model complexity were already sufficient.

We also tested different levels of data augmentation (`none`, `basic`, `strong`) during training. While useful for experimentation, these variations showed little impact on final model performance.

A key insight came from our threshold analysis (`threshold_analysis.ipynb`), where we evaluated the trade-off between false positives (FP) and false negatives (FN). Since false negatives carry a higher risk in medical diagnostics, we adjusted the modelâ€™s decision threshold from 0.50 to 0.35. This reduced FN from 48 to 33 with a reasonable increase in FP, resulting in a more appropriate balance for malaria detection use cases.

The script `evaluate.py` evaluates the best-performing model and reports results for both:
- the standard threshold of 0.50
- the adjusted threshold of 0.35 (predefined based on prior analysis)

All code, trained models, and analysis results are included for full reproducibility.


### Structured project directory
```
â”œâ”€â”€ data/                       # Sample data or processing scripts (NOT the entire dataset)
â”‚   â”œâ”€â”€ data_loader.py              # Data loading and transformation
â”‚   â”œâ”€â”€ malaria_optuna.db           # Optuna study database
â”œâ”€â”€ analysis/                   # Jupyter notebooks and scripts for analysis
â”‚   â”œâ”€â”€ data_expd.ipynb             # Exploratory data analysis
â”‚   â”œâ”€â”€ hyperparam.ipynb            # Hyperparameter analysis
â”‚   â”œâ”€â”€ LIME_explanation.py         # LIME exploration script
â”‚   â”œâ”€â”€ threshold_analysis.ipynb    # Threshold decision analysis
â”œâ”€â”€ src/                        # Main scripts for training and evaluation
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluate the best model
â”‚   â”œâ”€â”€ hyperparam_search.py        # Hyperparameter tuning with Optuna
â”‚   â”œâ”€â”€ test_model.py               # Model testing script
â”‚   â”œâ”€â”€ train_model_cv.py           # Model training with K-Fold cross-validation
â”‚   â”œâ”€â”€ train_model.py              # Model training with predefined split
â”œâ”€â”€ models/                     # Saved model weights and architectures
â”‚   â”œâ”€â”€ best_malaria_model_*        # Best model from each run
â”‚   â”œâ”€â”€ malaria_model_1.py          # Base model
â”‚   â”œâ”€â”€ malaria_model_flex.py       # Flexible model, configurable via Optuna
â”œâ”€â”€ report/                     # Final report and related documentation
â”‚   â”œâ”€â”€ analysis_plots/             # Plots from exploratory and performance analysis
â”‚   â”œâ”€â”€ performance_plots/          # Visualizations from Weights & Biases
â”œâ”€â”€ requirements.txt            # List of Python dependencies
â”œâ”€â”€ README.md                   # Instructions for using the project
â”œâ”€â”€ results/                    # Evaluation results
â”‚   â”œâ”€â”€ evaluation_best_*           # Evaluation outputs per model
â”œâ”€â”€ wandb/                      # Weights & Biases log directory
â”œâ”€â”€ env.yaml                    # Conda environment definition file
â”œâ”€â”€ LICENSE                     # License file
â””â”€â”€ README.md                   # Project overview and usage instructions
```


---


## Dataset Details (Source & Statistics)

The dataset used in this project is publicly available on Kaggle:  
https://www.kaggle.com/datasets/maestroalert/malaria-split-dataset/data

It contains cell images labeled as either **Parasitized** or **Uninfected**, already split into training, validation, and test sets.

### File Type Summary
- Total image files: **27,558**
- Format: `.png` only

### Number of Images per Class
| Set        | Parasitized | Uninfected | Total  |
|------------|-------------|------------|--------|
| Train      | 11,024      | 11,024     | 22,048 |
| Validation | 1,378       | 1,377      | 2,755  |
| Test       | 1,377       | 1,378      | 2,755  |
| **Total**  | **13,779**  | **13,779** | **27,558** |

### Image Dimension Analysis
- Images vary in size, with most clustered around **128Ã—128 pixels**.
- Resizing to **128Ã—128** was chosen for model input consistency.
- (See plots in `analysis/data_expd.ipynb` for more details.)

### RGB Mean & Std (All Sets Combined)
Calculated across all train, validation, and test images:

- **Mean:** `[0.5295, 0.4239, 0.4530]`
- **Std:** `[0.3323, 0.2682, 0.2821]`

These values were used to normalize images during preprocessing.


---


## Data Preprocessing

Before feeding the images into the neural network, a set of preprocessing and transformation steps is applied to ensure consistent input dimensions and improve model generalization.

### Common Preprocessing Steps (All Sets)
- **Resize:** All images are resized to **128Ã—128 pixels** to standardize input dimensions.
- **Normalization:** Images are normalized using the RGB mean and standard deviation computed over the entire dataset:
  - `mean = [0.529, 0.424, 0.453]`
  - `std = [0.332, 0.268, 0.282]`
  - This scales pixel values to approximately the range [-1, 1].

### Data Augmentation (Train Set Only)
To improve generalization and prevent overfitting, several augmentation strategies can be applied to the training set via the `aug_level` parameter:

| Augmentation Level | Transformations Applied                                                                       |
|--------------------|-----------------------------------------------------------------------------------------------|
| `none`             | Resize â†’ ToTensor â†’ Normalize                                                                 |
| `basic` *(default)*| Resize â†’ RandomHorizontalFlip â†’ RandomRotation(+-15Â°) â†’ ToTensor â†’ Normalize                  |
| `strong`           | Resize â†’ RandomHorizontalFlip/VerticalFlip â†’ RandomRotation(+-180Â°) â†’ ColorJitter â†’ Normalize |

These options can be set via the `get_train_transform()` function.

### Dataloader Setup
- Images are loaded using `torchvision.datasets.ImageFolder()`, which automatically assigns:
  - `0 = Parasitized` (based on folder name)
  - `1 = Uninfected`
- Data is then wrapped into PyTorch `DataLoader` objects with batching and shuffling enabled (for training).
- Validation and test sets are never augmented and use only resizing and normalization.

### Data Path Handling
The dataset root path is stored in a separate `data_path.txt` file (not tracked by Git).  
This path is automatically loaded via a utility function to keep code clean and portable.

---

> ðŸ“Œ Example:  
> You can create all data loaders by calling:  
> `train_loader, val_loader, test_loader = create_dataloaders(aug_level="basic", batch_size=32)`


---


## Installation and usage instructions
### Data download
1. Download the dataset from: https://www.kaggle.com/datasets/maestroalert/malaria-split-dataset/data

After extraction, the directory structure should look like this:
```
â”œâ”€â”€ your_data_path/data/ 
    â”œâ”€â”€ test
        â”œâ”€â”€ Parasitized
        â”œâ”€â”€ Uninfected
    â”œâ”€â”€ train
        â”œâ”€â”€ Parasitized
        â”œâ”€â”€ Uninfected
    â”œâ”€â”€ val
        â”œâ”€â”€ Parasitized
        â”œâ”€â”€ Uninfected
```

2. Replace `your_data_path` with the actual path to your data.
3. Create a file named `data_path.txt` and store your local data path in it.

### Environment Management: Setting up the Environment
To create and activate the Conda environment from the `env.yaml` file, run:
```
conda env create --file env.yaml
conda activate DSHEAL_proj1_GaMo
```


---


## Evaluation
To evaluate the best model (or alternatively test all models in the models/ directory), run:
```
python src\evaluate.py --data_path "your_data_path/data"
```
Replace "your_data_path/data" with the actual path to your dataset.


---


## Model performance summary

Evaluation Results for model: best_malaria_model_attmy8cd_epoch7

=== wandb ARGS ===
--aug_level: basic

=== Classification Report ===
              precision    recall  f1-score   support

  Uninfected     0.9640    0.9339    0.9487      1377
 Parasitized     0.9360    0.9652    0.9503      1378

    accuracy                         0.9495      2755
   macro avg     0.9500    0.9495    0.9495      2755
weighted avg     0.9500    0.9495    0.9495      2755

=== Confusion Matrix ===
[[1286   91]
 [  48 1330]]

*** AFTER ADJUSTING CALCULATED THRESHOLD (0.35) ****
              precision    recall  f1-score   support

  Uninfected     0.9746    0.9187    0.9458      1377
 Parasitized     0.9231    0.9761    0.9489      1378

    accuracy                         0.9474      2755
   macro avg     0.9489    0.9474    0.9473      2755
weighted avg     0.9488    0.9474    0.9473      2755

[[1265  112]
 [  33 1345]]


---


## Team members and contributions
**Mike Gasser**  
ZHAW School of Engineering  
gassemik@students.zhaw.ch  

**Andres Mock**  
ZHAW School of Engineering  
mockand1@students.zhaw.ch



